\chapter*{Conclusions}
\addcontentsline{toc}{chapter}{Conclusion}
\label{chap:IV-0-conclusions}

  The work exposed in this PhD thesis details the contribution of the author to the development, testing, and characterization of the DAQ system of the Triple-GEM upgrade project for the muon spectrometer of CMS. This upgrade aims at improving the triggering and reconstruction performances of CMS after the increase in luminosity of the LHC foreseen for 2018-2019. Through the installation of a ring of GEM detectors in both endcaps of CMS, the CMS GEM collaboration proposes to increase the redundancy of the muon spectrometer and combine the results of the GEMs and the CSCs. To this end, a novel DAQ system was designed and tested. \\

  In the early stages of the project, our developments focused on the design of a robust yet flexible firmware architecture for the OptoHybrid in charge of the communication between the analog front-end and the off-detector electronics. When tested during test beam campaigns at CERN and coupled to the VFAT2 front-end and GLIB AMC, we built a dedicated software suite in order to control and monitor the systems. Using the data recorded by the detector and the analysis we developed, we were able to obtain measurements of the efficiency of the detector according to various parameters. We obtained a single chamber efficiency of 97\% and tested the rate capability up until a trigger rate of 120 kHz with a resulting efficiency of 96\%. The analysis we have performed show that the GEM detectors equipped with the DAQ system we have designed meet the requirements of the project regarding the efficiency and the rate capability of the chambers. \\

  Our developments then shifted towards the qualification of the electronic systems for their installation in CMS. To automate the characterization of the components, we developed a data analysis tool which makes use of the full extend of the VFAT2 capabilities to perform the bias and analysis of the analog front-end. The procedure is used to detect faulty units, and characterize and align the analog response of the chip channel by channel. We quantified the noise of the electronics on the channels to 624 $\pm$ 62 e$^-$ and determine that the dispersion of the channels was reduced from 0.10 fC to 0.02 fC. To test the GEB, we created a small PCB board that can be used to test each position to detect faults in the manufacturing or soldering. The board relies on an FPGA coupled with an MCU to communicate with the OptoHybrid and test the integrity of the transmitted signals. Finally, the system as a whole was tested using a Python script which targets specific components of the architectures. The tools and procedures we created are still in use for the preparation of the integration test to select appropriate components and install testing facilities at CERN and in other associated research laboratories. \\

  Lastly, we studied the impact of radiation on the FPGA of the OptoHybrid by exposing it to proton beams. To this end, we developed custom firmware in order to compute the interaction cross section with the various components inside the chip and to study the effectiveness of mitigation techniques. After the tests were performed and the data analyzed by our analysis software, we obtained an interaction cross section of 3.08 $ \times $ 10$^{-7}$ cm$^{2}$ and 1.02 $ \times $ 10$^{-7}$ cm$^{2}$ for the configuration memory of the FPGA and the BRAM respectively, the two main sources of errors. These values were obtained for protons of 62 MeV which display the same behavior as neutrons, prominent background in CMS. From these results, we calculated the rate of errors that the FPGAs will encounter in the GE1/1 station. This yielded a rate of 33.2 errors and 11 errors a day per FPGA for the configuration memory and the BRAM respectively. Although elevated, these errors can be mitigated using the techniques we studied. Indeed, these showed to be efficient at particle fluxes below 5 $ \times $ 10$^4$ particles cm$^{-2}$ s$^{-1}$. Finally, a total dose of 84 krad was accumulated over the course of the tests, corresponding to a dose 8 times higher than what will be collected during the totality of the LHC Phase II. We did not observe any increase in the interaction cross section for the components of the FPGAs which continued to function correctly until the end of the tests. \\

  In parallel to our work on the GEM upgrade project, we also investigated novel DAQ systems that make use of new technologies to create an innovative architecture. To this end, we implemented two different DAQ systems that use different topologies to interconnect their nodes and handle the flow of data. The first one, the readout system of the 10 cm $ \times $ 10 cm GEM prototype, used a star network to control the various subsystems. In this configuration, data is pulled from node to node and systematically transits through the central computing node which becomes the bottleneck of the system. The DAQ system relied on a updating scheme with a high frequency of pull requests which increased the traffic on the network and impacted the speed of the communications. The second system implemented a two-way mesh network based on novel web technologies which allows for event driven functionalities. A direct connection between the server or client and the database was established to store information thus reducing the bandwidth used on the network and the strain on the central computing node. This architecture showed to bring improvements on various fronts of data and system management as it provided a truly event-driven architecture with a response time as low as 2.58 ms, 1 000 times faster than other DAQ systems.
